{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('base': conda)",
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "82ca40d01783b9f1dd9bc1a6595c8a905d6b29ba5678c87a898deaa2f1789d36"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Hello World\n"
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import cloudpickle\n",
    "from functools import wraps\n",
    "import time\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elapsed_time(func):\n",
    "    @wraps(func)\n",
    "    def out(*args, **kwargs):\n",
    "        init_time = time.time()\n",
    "        func(*args, **kwargs)\n",
    "        elapsed_time = time.time() - init_time\n",
    "        print(f\"Elapsed time of {func.__name__}: {elapsed_time:.4f}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@elapsed_time\n",
    "def print_hello():\n",
    "    time.sleep(1)\n",
    "    print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@elapsed_time\n",
    "def main_func():\n",
    "    parser = argparse.ArgumentParser(description='Train a Keras')\n",
    "    parser.add_argument('--batch-size', '-b', type=int, default=8)\n",
    "    parser.add_argument('--epochs', '-e', type=int, default = 2)\n",
    "    parser.add_argument('--learning-rate', '-l', type=float, default = 0.1)\n",
    "    parser.add_argument('--num-hidden-units', '-n', type=int, default=512)\n",
    "    parser.add_argument('--dropout', '-d', type=float, default=0.05)\n",
    "    parser.add_argument('--momentum', '-m', type=float, default=0.5)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    mlflow.log_param('batch_size', args.batch_size)\n",
    "    mlflow.log_param('epochs', args.epochs)\n",
    "    mlflow.log_param('learning_rate', args.learning_rate)\n",
    "\n",
    "    mnist = keras.datasets.mnist\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train/255.0, x_test/255.0\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=x_train[0].shape),\n",
    "        keras.layers.Dense(args.num_hidden_units, activation=tf.nn.relu),\n",
    "        keras.layers.Dropout(args.dropout),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(lr=args.learning_rate, \n",
    "    momentum=args.momentum, nesterov=True)\n",
    "\n",
    "    class LogMetricsCallback(keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            mlflow.log_metric('training_loss', logs['loss'], epoch)\n",
    "            mlflow.log_metric('training_accuracy', logs['accuracy'], epoch)\n",
    "\n",
    "\n",
    "    model.compile(optimizer=optimizer, \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "                epochs=args.epochs, batch_size=args.batch_size,\n",
    "                callbacks=[LogMetricsCallback()])\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "    mlflow.log_metric('test_loss', test_loss)\n",
    "    mlflow.log_metric('test_accuracy', test_acc)\n",
    "\n",
    "    mlflow.keras.log_model(model, artifact_path='keras-model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "usage: ipykernel_launcher [-h] [--batch-size BATCH_SIZE] [--epochs EPOCHS]\n                          [--learning-rate LEARNING_RATE]\n                          [--num-hidden-units NUM_HIDDEN_UNITS]\n                          [--dropout DROPOUT] [--momentum MOMENTUM]\nipykernel_launcher: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9013 --control=9011 --hb=9010 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"cdb8ce8e-5770-41a7-9254-47eff537fe62\" --shell=9012 --transport=\"tcp\" --iopub=9014 --f=/var/folders/0s/6831mwss3ngbr2rh0337_18r0000gn/T/tmp-87154lf3qzC81RlCA.json\n"
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "2",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "main_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}